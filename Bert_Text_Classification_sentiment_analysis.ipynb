{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Project-1 cifar100 classification"
      ],
      "metadata": {
        "id": "4klpUerHzc1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels, num_classes=100)\n",
        "test_labels = to_categorical(test_labels, num_classes=100)\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=100, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STtLQmngzaFh",
        "outputId": "7b7d49a7-bc1b-42fa-9457-6c95db5730b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 6s 0us/step\n",
            "Epoch 1/100\n",
            "625/625 [==============================] - 9s 7ms/step - loss: 4.1339 - accuracy: 0.0664 - val_loss: 3.8705 - val_accuracy: 0.1059\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.5799 - accuracy: 0.1481 - val_loss: 3.4639 - val_accuracy: 0.1693\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.2660 - accuracy: 0.2080 - val_loss: 3.1866 - val_accuracy: 0.2236\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 3.0584 - accuracy: 0.2460 - val_loss: 3.0218 - val_accuracy: 0.2562\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.9098 - accuracy: 0.2749 - val_loss: 2.9539 - val_accuracy: 0.2648\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.7867 - accuracy: 0.2999 - val_loss: 2.8887 - val_accuracy: 0.2844\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.6852 - accuracy: 0.3211 - val_loss: 2.8343 - val_accuracy: 0.2972\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 2.5902 - accuracy: 0.3402 - val_loss: 2.7501 - val_accuracy: 0.3098\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.5114 - accuracy: 0.3534 - val_loss: 2.7073 - val_accuracy: 0.3211\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.4416 - accuracy: 0.3697 - val_loss: 2.6649 - val_accuracy: 0.3319\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.3790 - accuracy: 0.3828 - val_loss: 2.6731 - val_accuracy: 0.3308\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 2.3188 - accuracy: 0.3958 - val_loss: 2.6076 - val_accuracy: 0.3431\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.2614 - accuracy: 0.4103 - val_loss: 2.6310 - val_accuracy: 0.3379\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.2178 - accuracy: 0.4168 - val_loss: 2.6036 - val_accuracy: 0.3470\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.1693 - accuracy: 0.4267 - val_loss: 2.5760 - val_accuracy: 0.3579\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 2.1316 - accuracy: 0.4353 - val_loss: 2.5974 - val_accuracy: 0.3491\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.0892 - accuracy: 0.4420 - val_loss: 2.6333 - val_accuracy: 0.3450\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 2.0451 - accuracy: 0.4546 - val_loss: 2.6009 - val_accuracy: 0.3578\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 2.0158 - accuracy: 0.4591 - val_loss: 2.6168 - val_accuracy: 0.3592\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.9847 - accuracy: 0.4660 - val_loss: 2.6397 - val_accuracy: 0.3538\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.9450 - accuracy: 0.4744 - val_loss: 2.6186 - val_accuracy: 0.3544\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.9141 - accuracy: 0.4840 - val_loss: 2.6422 - val_accuracy: 0.3556\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.8874 - accuracy: 0.4882 - val_loss: 2.6950 - val_accuracy: 0.3455\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.8505 - accuracy: 0.4976 - val_loss: 2.6624 - val_accuracy: 0.3521\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.8204 - accuracy: 0.5051 - val_loss: 2.6811 - val_accuracy: 0.3484\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.7961 - accuracy: 0.5094 - val_loss: 2.7246 - val_accuracy: 0.3534\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.7626 - accuracy: 0.5161 - val_loss: 2.7339 - val_accuracy: 0.3641\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.7391 - accuracy: 0.5203 - val_loss: 2.7661 - val_accuracy: 0.3525\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.7146 - accuracy: 0.5277 - val_loss: 2.7978 - val_accuracy: 0.3540\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.6872 - accuracy: 0.5344 - val_loss: 2.8038 - val_accuracy: 0.3443\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 1.6660 - accuracy: 0.5393 - val_loss: 2.8352 - val_accuracy: 0.3496\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.6382 - accuracy: 0.5451 - val_loss: 2.8822 - val_accuracy: 0.3542\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.6230 - accuracy: 0.5495 - val_loss: 2.8799 - val_accuracy: 0.3451\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.5987 - accuracy: 0.5533 - val_loss: 2.9145 - val_accuracy: 0.3451\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.5694 - accuracy: 0.5634 - val_loss: 2.9585 - val_accuracy: 0.3436\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.5546 - accuracy: 0.5652 - val_loss: 2.9476 - val_accuracy: 0.3396\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.5332 - accuracy: 0.5714 - val_loss: 2.9824 - val_accuracy: 0.3439\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 1.5141 - accuracy: 0.5743 - val_loss: 3.0136 - val_accuracy: 0.3448\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.4900 - accuracy: 0.5804 - val_loss: 3.0749 - val_accuracy: 0.3439\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.4748 - accuracy: 0.5826 - val_loss: 3.1161 - val_accuracy: 0.3319\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.4634 - accuracy: 0.5833 - val_loss: 3.0638 - val_accuracy: 0.3416\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.4407 - accuracy: 0.5917 - val_loss: 3.1572 - val_accuracy: 0.3319\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.4245 - accuracy: 0.5972 - val_loss: 3.2149 - val_accuracy: 0.3330\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.4035 - accuracy: 0.5987 - val_loss: 3.2634 - val_accuracy: 0.3301\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.3900 - accuracy: 0.6030 - val_loss: 3.2348 - val_accuracy: 0.3304\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.3706 - accuracy: 0.6082 - val_loss: 3.3364 - val_accuracy: 0.3284\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.3571 - accuracy: 0.6097 - val_loss: 3.3180 - val_accuracy: 0.3314\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.3400 - accuracy: 0.6144 - val_loss: 3.3701 - val_accuracy: 0.3283\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.3217 - accuracy: 0.6160 - val_loss: 3.3697 - val_accuracy: 0.3287\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.3140 - accuracy: 0.6243 - val_loss: 3.4040 - val_accuracy: 0.3256\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.2891 - accuracy: 0.6250 - val_loss: 3.4555 - val_accuracy: 0.3214\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.2766 - accuracy: 0.6302 - val_loss: 3.5289 - val_accuracy: 0.3167\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.2763 - accuracy: 0.6280 - val_loss: 3.5345 - val_accuracy: 0.3200\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2499 - accuracy: 0.6359 - val_loss: 3.6342 - val_accuracy: 0.3260\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.2374 - accuracy: 0.6394 - val_loss: 3.6330 - val_accuracy: 0.3218\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.2250 - accuracy: 0.6421 - val_loss: 3.6768 - val_accuracy: 0.3144\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2126 - accuracy: 0.6454 - val_loss: 3.6942 - val_accuracy: 0.3184\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.1942 - accuracy: 0.6513 - val_loss: 3.7508 - val_accuracy: 0.3137\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.1877 - accuracy: 0.6507 - val_loss: 3.8030 - val_accuracy: 0.3192\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.1701 - accuracy: 0.6569 - val_loss: 3.8018 - val_accuracy: 0.3184\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.1627 - accuracy: 0.6588 - val_loss: 3.8162 - val_accuracy: 0.3144\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.1452 - accuracy: 0.6616 - val_loss: 3.9187 - val_accuracy: 0.3153\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.1470 - accuracy: 0.6596 - val_loss: 3.9838 - val_accuracy: 0.3079\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.1241 - accuracy: 0.6680 - val_loss: 4.0120 - val_accuracy: 0.3058\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.1170 - accuracy: 0.6683 - val_loss: 4.0081 - val_accuracy: 0.3054\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.1072 - accuracy: 0.6698 - val_loss: 4.0760 - val_accuracy: 0.3080\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0860 - accuracy: 0.6757 - val_loss: 4.1472 - val_accuracy: 0.3026\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0892 - accuracy: 0.6734 - val_loss: 4.1275 - val_accuracy: 0.3064\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 1.0713 - accuracy: 0.6816 - val_loss: 4.1782 - val_accuracy: 0.3030\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 1.0614 - accuracy: 0.6827 - val_loss: 4.1890 - val_accuracy: 0.3070\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0490 - accuracy: 0.6862 - val_loss: 4.3485 - val_accuracy: 0.2944\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0363 - accuracy: 0.6896 - val_loss: 4.3151 - val_accuracy: 0.3001\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0316 - accuracy: 0.6898 - val_loss: 4.3674 - val_accuracy: 0.3053\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0302 - accuracy: 0.6908 - val_loss: 4.4056 - val_accuracy: 0.2981\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0090 - accuracy: 0.6966 - val_loss: 4.4974 - val_accuracy: 0.2977\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0042 - accuracy: 0.6953 - val_loss: 4.5382 - val_accuracy: 0.2981\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9902 - accuracy: 0.7022 - val_loss: 4.5506 - val_accuracy: 0.3004\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9866 - accuracy: 0.7004 - val_loss: 4.6185 - val_accuracy: 0.2978\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9785 - accuracy: 0.7020 - val_loss: 4.7094 - val_accuracy: 0.2989\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9638 - accuracy: 0.7089 - val_loss: 4.7178 - val_accuracy: 0.2923\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9532 - accuracy: 0.7109 - val_loss: 4.7476 - val_accuracy: 0.2973\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9477 - accuracy: 0.7149 - val_loss: 4.8646 - val_accuracy: 0.2936\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9372 - accuracy: 0.7154 - val_loss: 4.8416 - val_accuracy: 0.2943\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9263 - accuracy: 0.7218 - val_loss: 4.9338 - val_accuracy: 0.2930\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9221 - accuracy: 0.7196 - val_loss: 4.9779 - val_accuracy: 0.2878\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9136 - accuracy: 0.7206 - val_loss: 4.8342 - val_accuracy: 0.2853\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9040 - accuracy: 0.7242 - val_loss: 4.9631 - val_accuracy: 0.2927\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8980 - accuracy: 0.7247 - val_loss: 5.1157 - val_accuracy: 0.2895\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8861 - accuracy: 0.7298 - val_loss: 5.2505 - val_accuracy: 0.2841\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9008 - accuracy: 0.7226 - val_loss: 5.1596 - val_accuracy: 0.2907\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8830 - accuracy: 0.7285 - val_loss: 5.3353 - val_accuracy: 0.2868\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8829 - accuracy: 0.7261 - val_loss: 5.2211 - val_accuracy: 0.2856\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8510 - accuracy: 0.7386 - val_loss: 5.3708 - val_accuracy: 0.2913\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.8527 - accuracy: 0.7376 - val_loss: 5.4039 - val_accuracy: 0.2876\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8490 - accuracy: 0.7379 - val_loss: 5.4911 - val_accuracy: 0.2854\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8444 - accuracy: 0.7377 - val_loss: 5.4249 - val_accuracy: 0.2840\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.8333 - accuracy: 0.7419 - val_loss: 5.6092 - val_accuracy: 0.2859\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8291 - accuracy: 0.7435 - val_loss: 5.6096 - val_accuracy: 0.2915\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8378 - accuracy: 0.7391 - val_loss: 5.6510 - val_accuracy: 0.2833\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8194 - accuracy: 0.7444 - val_loss: 5.7106 - val_accuracy: 0.2888\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 5.6272 - accuracy: 0.2918\n",
            "Test accuracy: 0.29179999232292175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## project-2 sentiment analysis"
      ],
      "metadata": {
        "id": "gmtgJhFT2-is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hGxl1Bl28iF",
        "outputId": "dee302de-ac96-4803-9e56-7a0397cdcdc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "D_CeD0xI5o0x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "path = \"/content/training.1600000.processed.noemoticon.csv\"\n",
        "\n",
        "# Use csv.reader() instead of pd.read_csv()\n",
        "with open(path, 'r', encoding='ISO-8859-1') as file:\n",
        "    reader = csv.reader(file, delimiter=',', quotechar='\"')\n",
        "    data = list(reader)\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "df = pd.DataFrame(data[1:], columns=data[0])"
      ],
      "metadata": {
        "id": "ZWMCEpRu5b-V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "A44A_JQd54bD",
        "outputId": "372049bd-e30d-4501-d272-e1c5de859bc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
              "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
              "...    ..         ...                           ...       ...   \n",
              "884148  4  1686251752  Sun May 03 04:33:11 PDT 2009  NO_QUERY   \n",
              "884149  4  1686251761  Sun May 03 04:33:11 PDT 2009  NO_QUERY   \n",
              "884150  4  1686251814  Sun May 03 04:33:13 PDT 2009  NO_QUERY   \n",
              "884151  4  1686251883  Sun May 03 04:33:14 PDT 2009  NO_QUERY   \n",
              "884152  4  1686251914  Sun May 03 04:33:15 PDT 2009  NO_QUERY   \n",
              "\n",
              "        _TheSpecialOne_  \\\n",
              "0         scotthamilton   \n",
              "1              mattycus   \n",
              "2               ElleCTF   \n",
              "3                Karoli   \n",
              "4              joy_wolf   \n",
              "...                 ...   \n",
              "884148  ZombiAnnaNicole   \n",
              "884149      LindaSmilez   \n",
              "884150             thep   \n",
              "884151           nisaho   \n",
              "884152           x3Flor   \n",
              "\n",
              "       @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
              "0       is upset that he can't update his Facebook by ...                                                                   \n",
              "1       @Kenichan I dived many times for the ball. Man...                                                                   \n",
              "2         my whole body feels itchy and like its on fire                                                                    \n",
              "3       @nationwideclass no, it's not behaving at all....                                                                   \n",
              "4                           @Kwesidei not the whole crew                                                                    \n",
              "...                                                   ...                                                                   \n",
              "884148  @jenna_valentine I'm too high to respond to th...                                                                   \n",
              "884149          Chillin in the garden in Westend...sweet                                                                    \n",
              "884150  Whack, @epicsoul went home w/o biting me donut...                                                                   \n",
              "884151         off to watch XMEN: the last stand.  brb ^^                                                                   \n",
              "884152                                               None                                                                   \n",
              "\n",
              "[884153 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f27c9916-fc9f-40ef-b0ba-65282a772530\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884148</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251752</td>\n",
              "      <td>Sun May 03 04:33:11 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ZombiAnnaNicole</td>\n",
              "      <td>@jenna_valentine I'm too high to respond to th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884149</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251761</td>\n",
              "      <td>Sun May 03 04:33:11 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>LindaSmilez</td>\n",
              "      <td>Chillin in the garden in Westend...sweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884150</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251814</td>\n",
              "      <td>Sun May 03 04:33:13 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>thep</td>\n",
              "      <td>Whack, @epicsoul went home w/o biting me donut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884151</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251883</td>\n",
              "      <td>Sun May 03 04:33:14 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>nisaho</td>\n",
              "      <td>off to watch XMEN: the last stand.  brb ^^</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884152</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251914</td>\n",
              "      <td>Sun May 03 04:33:15 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>x3Flor</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>884153 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f27c9916-fc9f-40ef-b0ba-65282a772530')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f27c9916-fc9f-40ef-b0ba-65282a772530 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f27c9916-fc9f-40ef-b0ba-65282a772530');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-642bdba9-75c2-4853-bc27-8c146367bd70\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-642bdba9-75c2-4853-bc27-8c146367bd70')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-642bdba9-75c2-4853-bc27-8c146367bd70 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_14ec228d-215e-4ca1-9fad-5f806e6be42d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_14ec228d-215e-4ca1-9fad-5f806e6be42d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']"
      ],
      "metadata": {
        "id": "A2DZ98cF57cq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "ZB48jWLf6aLG",
        "outputId": "fa933023-deec-4c44-973a-98f26915f282"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       target         ids                          date      flag  \\\n",
              "0           0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "1           0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "2           0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "3           0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4           0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
              "...       ...         ...                           ...       ...   \n",
              "884148      4  1686251752  Sun May 03 04:33:11 PDT 2009  NO_QUERY   \n",
              "884149      4  1686251761  Sun May 03 04:33:11 PDT 2009  NO_QUERY   \n",
              "884150      4  1686251814  Sun May 03 04:33:13 PDT 2009  NO_QUERY   \n",
              "884151      4  1686251883  Sun May 03 04:33:14 PDT 2009  NO_QUERY   \n",
              "884152      4  1686251914  Sun May 03 04:33:15 PDT 2009  NO_QUERY   \n",
              "\n",
              "                   user                                               text  \n",
              "0         scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "1              mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "2               ElleCTF    my whole body feels itchy and like its on fire   \n",
              "3                Karoli  @nationwideclass no, it's not behaving at all....  \n",
              "4              joy_wolf                      @Kwesidei not the whole crew   \n",
              "...                 ...                                                ...  \n",
              "884148  ZombiAnnaNicole  @jenna_valentine I'm too high to respond to th...  \n",
              "884149      LindaSmilez          Chillin in the garden in Westend...sweet   \n",
              "884150             thep  Whack, @epicsoul went home w/o biting me donut...  \n",
              "884151           nisaho         off to watch XMEN: the last stand.  brb ^^  \n",
              "884152           x3Flor                                               None  \n",
              "\n",
              "[884153 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c96616a-e878-46d5-9d61-e50740d2fe5c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884148</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251752</td>\n",
              "      <td>Sun May 03 04:33:11 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ZombiAnnaNicole</td>\n",
              "      <td>@jenna_valentine I'm too high to respond to th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884149</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251761</td>\n",
              "      <td>Sun May 03 04:33:11 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>LindaSmilez</td>\n",
              "      <td>Chillin in the garden in Westend...sweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884150</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251814</td>\n",
              "      <td>Sun May 03 04:33:13 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>thep</td>\n",
              "      <td>Whack, @epicsoul went home w/o biting me donut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884151</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251883</td>\n",
              "      <td>Sun May 03 04:33:14 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>nisaho</td>\n",
              "      <td>off to watch XMEN: the last stand.  brb ^^</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884152</th>\n",
              "      <td>4</td>\n",
              "      <td>1686251914</td>\n",
              "      <td>Sun May 03 04:33:15 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>x3Flor</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>884153 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c96616a-e878-46d5-9d61-e50740d2fe5c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c96616a-e878-46d5-9d61-e50740d2fe5c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c96616a-e878-46d5-9d61-e50740d2fe5c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9aad4ab0-ccbf-4854-ab77-d918cef3b3e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9aad4ab0-ccbf-4854-ab77-d918cef3b3e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9aad4ab0-ccbf-4854-ab77-d918cef3b3e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2a649131-6833-45a3-a3da-63dd2c69ab6e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2a649131-6833-45a3-a3da-63dd2c69ab6e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "# Concatenate text samples from X_train and X_test\n",
        "all_texts = list(X_train.astype(str)) + list(X_test.astype(str))\n",
        "\n",
        "# Tokenize and encode sequences\n",
        "encodings = tokenizer(all_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Split the encodings back into train and test sets\n",
        "train_encodings = {key: val[:len(X_train)] for key, val in encodings.items()}\n",
        "test_encodings = {key: val[len(X_train):] for key, val in encodings.items()}\n",
        "\n",
        "# Create DataLoader for training and testing sets\n",
        "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']),\n",
        "                              torch.tensor(train_encodings['attention_mask']),\n",
        "                              torch.squeeze(torch.tensor(y_train.tolist())))\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']),\n",
        "                             torch.tensor(test_encodings['attention_mask']),\n",
        "                             torch.squeeze(torch.tensor(y_test.tolist())))\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Set device (GPU if available, otherwise CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Fine-tuning BERT model\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = (t.to(device) for t in batch)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "total_preds = []\n",
        "total_labels = []\n",
        "for batch in test_loader:\n",
        "    input_ids, attention_mask, labels = (t.to(device) for t in batch)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        total_preds.extend(preds)\n",
        "        total_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (np.array(total_preds) == np.array(total_labels)).mean()\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "h2SF5QmF3hWd",
        "outputId": "eda129ed-3173-4d7c-d177-44aeb2f7162b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-15-6c0413070194>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']),\n",
            "<ipython-input-15-6c0413070194>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(train_encodings['attention_mask']),\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many dimensions 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6c0413070194>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']),\n\u001b[1;32m     29\u001b[0m                               \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                               torch.tensor(y_train.tolist()))\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load dataset\n",
        "path = \"/content/training.1600000.processed.noemoticon.csv\"\n",
        "df = pd.read_csv(path, encoding='ISO-8859-1', header=None,\n",
        "                 names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
        "\n",
        "# Map target values to negative, neutral, and positive\n",
        "df['sentiment'] = df['target'].map({0: 'negative', 2: 'neutral', 4: 'positive'})\n",
        "\n",
        "# Data preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
        "    # Remove mentions and hashtags\n",
        "    text = re.sub(r'\\@\\w+|\\#\\w+', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Tokenization and stopwords removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Model training\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Model evaluation\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJMF1133_woZ",
        "outputId": "1679e038-2711-40c7-9352-a25feffee415"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.784275\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.77      0.78    159494\n",
            "    positive       0.78      0.80      0.79    160506\n",
            "\n",
            "    accuracy                           0.78    320000\n",
            "   macro avg       0.78      0.78      0.78    320000\n",
            "weighted avg       0.78      0.78      0.78    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr2qyZGa0tGE"
      },
      "source": [
        "## 1: Exploratory Data Analysis and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y54dbt7H05Zp",
        "outputId": "dd388a02-abcc-42b1-b410-f6f428bf7dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch #no change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqIuXSbo0tGG"
      },
      "outputs": [],
      "source": [
        "import torch #no change\n",
        "from tqdm.notebook import tqdm #no change\n",
        "import numpy as np #no change\n",
        "import pandas as pd #no change\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/training.1600000.processed.noemoticon.csv',encoding='latin-1') #change\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "gmZ4k77KMvid",
        "outputId": "33676121-424b-4e69-ae36-85a454e1977f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/training.1600000.processed.noemoticon.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-308d405fcf2e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/training.1600000.processed.noemoticon.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/training.1600000.processed.noemoticon.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g4PHSND0tGM"
      },
      "outputs": [],
      "source": [
        "df.head() #no change"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['sentiments','Id','date_time','Query','user','reviews']"
      ],
      "metadata": {
        "id": "zrVKpXyBpwSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyQx3m5TSWRY"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['sentiments','reviews']]"
      ],
      "metadata": {
        "id": "aMSz60u30ohK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "qtivavz81Jhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1NeKjJEH4Az"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgJJKcavC3bO"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['DV','IV']"
      ],
      "metadata": {
        "id": "Et8fjy7ukRyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XOfdqvL0tGQ"
      },
      "outputs": [],
      "source": [
        "set(df.DV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFS97cXY0tGS"
      },
      "outputs": [],
      "source": [
        "df.DV.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i1tO0Id0tGU"
      },
      "outputs": [],
      "source": [
        "# Assuming df is your DataFrame\n",
        "class_counts = df['DV'].value_counts()\n",
        "classes_to_keep = class_counts[class_counts > 30].index\n",
        "df = df[df['DV'].isin(classes_to_keep)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKWJEaTZ0tGV"
      },
      "outputs": [],
      "source": [
        "df.DV.value_counts() #change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI9nSaKKx4Rz"
      },
      "outputs": [],
      "source": [
        "df.DV.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI-PGGVo0tGX"
      },
      "outputs": [],
      "source": [
        "possible_labels = df.DV.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEkyhrh01vWu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty-3wUq71vaB"
      },
      "outputs": [],
      "source": [
        "possible_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvrEDHlKyBTh"
      },
      "outputs": [],
      "source": [
        "lst = ['a','b']\n",
        "dct = {}\n",
        "for index, character in enumerate(lst):\n",
        "   print(index,\" \",character)\n",
        "   dct[character] = index\n",
        "print(dct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_X810_k0tGZ"
      },
      "outputs": [],
      "source": [
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCXobP2H0tGa"
      },
      "outputs": [],
      "source": [
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm59s7AI2lqI"
      },
      "outputs": [],
      "source": [
        "df.DV.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIbrWlEf0tGc"
      },
      "outputs": [],
      "source": [
        "df.DV = df['DV'].map(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7OvMH9_2ktz"
      },
      "outputs": [],
      "source": [
        "df.DV.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu-4z8520tGd"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEnLf9II0tGe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf8fvbvE0tGf"
      },
      "source": [
        "## 2: Training/Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02WrPgiQ0tGg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KdZgdoj0tGh"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.DV.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.DV.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AKea9UHf-PX"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdoBe_bRTg5Y"
      },
      "outputs": [],
      "source": [
        "X_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDwDml553GKg"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5RpBtKfXrM5"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSH93qaNzZFs"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdMKJXk7TuvJ"
      },
      "outputs": [],
      "source": [
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0ysvhJa0tGj"
      },
      "outputs": [],
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN22qkP_0tGj"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "691lyhGD0tGl"
      },
      "outputs": [],
      "source": [
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pTeUxCg0tGm"
      },
      "outputs": [],
      "source": [
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHZ1dcTKzubJ"
      },
      "outputs": [],
      "source": [
        "df[df['data_type']==\"val\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SHLipj30AFm"
      },
      "outputs": [],
      "source": [
        "possible_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lqsg5Ps0tGn"
      },
      "outputs": [],
      "source": [
        "df.groupby(['DV', 'data_type']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcfAfE300tGo"
      },
      "source": [
        "# 3. Loading Tokenizer and Encoding our Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSi-zABR0tGp"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV-zDsKw0tGq"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "524M3-Zy0tGr"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased', #bert-base-uncased using small bert model for simple data , bert-large-uncased IT WILL USE LARGE MODEL fo large data\n",
        "    do_lower_case=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMG0Fm1c0tGs"
      },
      "outputs": [],
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "\n",
        "    df[df.data_type=='train'].IV.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='val'].IV.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].DV.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type=='val'].DV.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9y7AILN0tGv"
      },
      "outputs": [],
      "source": [
        "input_ids_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqp_l9_8WyZ-"
      },
      "outputs": [],
      "source": [
        "attention_masks_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwOk6D6H0tGw"
      },
      "outputs": [],
      "source": [
        "dataset_train = TensorDataset(input_ids_train,\n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val,\n",
        "                            attention_masks_val,\n",
        "                           labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nxNTQ2P0tGw"
      },
      "outputs": [],
      "source": [
        "len(dataset_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKLcLUd-0tGx"
      },
      "outputs": [],
      "source": [
        "dataset_train.tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLlgZpVp0tGy"
      },
      "source": [
        "# 4. Setting up BERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bI32PBTXi35"
      },
      "outputs": [],
      "source": [
        "len(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HfzQaGy0tGz"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtaabZon0tGz"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-base-uncased',\n",
        "                                      num_labels = len(label_dict),#2\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3yFPIjR0tG0"
      },
      "source": [
        "# 5. Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfnJ2cAi0tG1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnQ8IuZ40tG2"
      },
      "outputs": [],
      "source": [
        "dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmSjjprh0tG3"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs4n8utM0tG4"
      },
      "source": [
        "# 6. Setting Up Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l33htjXE0tG4"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUtG2_cb0tG5"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRU-dnA_0tG5"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx4E8G6g0tG6"
      },
      "source": [
        "# 7. Defining our Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNslycX10tG7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhqzpePg0tG7"
      },
      "outputs": [],
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YAkv_Ny0tG8"
      },
      "outputs": [],
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWbaOk6F0tG9"
      },
      "source": [
        "# 8. Creating our Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"CUDA is not available. The code requires CUDA to run.\")\n",
        "    exit()\n",
        "\n",
        "# Check if the seed value is valid\n",
        "if not isinstance(seed_val, int):\n",
        "    print(\"The seed value must be an integer.\")\n",
        "    exit()\n",
        "\n",
        "# Check if the seed value is within the valid range\n",
        "if seed_val < 0:\n",
        "    print(\"The seed value must be non-negative.\")\n",
        "    exit()\n",
        "\n",
        "# Check if the seed value is too large\n",
        "if seed_val > 2**32 - 1:\n",
        "    print(\"The seed value is too large.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "dMoQyEhWqN3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "puXZ_pIeqbbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "50X2ZZZYqexL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "Y_Fhqjf6qiAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    # Check the CUDA device count\n",
        "    device_count = torch.cuda.device_count()\n",
        "    print(f\"Number of CUDA devices: {device_count}\")\n",
        "\n",
        "# Check the CUDA version\n",
        "cuda_version = torch.version.cuda\n",
        "print(f\"CUDA version: {cuda_version}\")\n",
        "\n",
        "# Check the PyTorch version\n",
        "torch_version = torch.__version__\n",
        "print(f\"PyTorch version: {torch_version}\")"
      ],
      "metadata": {
        "id": "2Z9rqjsKq2pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!TORCH_USE_CUDA_DSA=1 python your_script.py"
      ],
      "metadata": {
        "id": "SWXZVZe5q-yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed value for the random number generator\n",
        "torch.manual_seed(seed_val)\n",
        "\n",
        "# Set the seed value for the CUDA random number generator\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "jWk2CUPUqRYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmqvX4gd0tG9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jDtqt8o0tG-"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHDnCcCs0tG_"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in tqdm(dataloader_val):\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwmTMrY40tHA"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train() #forward propagation\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train,\n",
        "                        desc='Epoch {:1d}'.format(epoch),\n",
        "                        leave=False,\n",
        "                        disable=False)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward() #backwardprop\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "    torch.save(model, f'BERT_ft_Epoch_{epoch}.model') #name of the model can be changed here\n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "\n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ],
      "metadata": {
        "id": "XICiE6_yo3Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
      ],
      "metadata": {
        "id": "HQMdg1AUpEN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "Ld1oaP7xpHrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr4FU8Eilpdy"
      },
      "source": [
        "# EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h_xVvQpls4D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_bX9uX5mCUR"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0STXYYg7GZrf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# tweets = [tweet1, tweet2, tweet3...]\n",
        "# for tweet in tweets:\n",
        "#   do who process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FBR4Rcrm1Wn"
      },
      "outputs": [],
      "source": [
        "headline = \"I love this product very much\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUW59eNHGvM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4TbF1byGMb3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBtEj43lnC54"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxn5rSDxnQo8"
      },
      "outputs": [],
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased', #bert-base-uncased using small bert model for simple data , bert-large-uncased fo large data\n",
        "    do_lower_case=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkoBZ7q9na-8"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txeMiNjVnj0A"
      },
      "outputs": [],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZYFRRGjnmbq"
      },
      "outputs": [],
      "source": [
        "encoded_headline = tokenizer(headline, return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y63SJtYvnuzS"
      },
      "outputs": [],
      "source": [
        "encoded_headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsj0BlUpnyFd"
      },
      "outputs": [],
      "source": [
        "input_ids = encoded_headline['input_ids'].to(device)\n",
        "attention_msk = encoded_headline['attention_mask'].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9doK3G7boBMJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm5iGFdOon7p"
      },
      "outputs": [],
      "source": [
        "path = '/content/BERT_ft_Epoch_1.model'\n",
        "model = torch.load(path, map_location = torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfBpi2t7o5d5"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ_vGTJqo6eY"
      },
      "outputs": [],
      "source": [
        "model_output = model(input_ids,attention_msk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEhaz-2zpbS_"
      },
      "outputs": [],
      "source": [
        "model_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNa8KrjypdOV"
      },
      "outputs": [],
      "source": [
        "model_output_tensor = torch.tensor(model_output.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4JIl0WApvkO"
      },
      "outputs": [],
      "source": [
        "model_output_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAheoxz4px0P"
      },
      "outputs": [],
      "source": [
        "model_output_tensor_categoryIndex = int(torch.argmax(model_output_tensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDFMNK_qqNLl"
      },
      "outputs": [],
      "source": [
        "model_output_tensor_categoryIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jyR9kg8qRpj"
      },
      "outputs": [],
      "source": [
        "# classes = {0: 'Non-biased', 1: 'Biased'}\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE0HY4Hklx6X"
      },
      "outputs": [],
      "source": [
        "swapped_dict = {0: 'neutral', 1: 'positive', 2: 'negative'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGN9pkH3l0vd"
      },
      "outputs": [],
      "source": [
        "swapped_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4GcDdtuqZ3A"
      },
      "outputs": [],
      "source": [
        "swapped_dict[model_output_tensor_categoryIndex]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahDl0o3uqc60"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"I love spending time with my family and friends.\",\n",
        "    \"The movie I watched yesterday was absolutely fantastic!\",\n",
        "    \"Today's weather is gloomy and depressing.\",\n",
        "    \"Learning new things is always exciting and fulfilling.\",\n",
        "    \"Traffic during rush hour drives me crazy; it's so frustrating.\",\n",
        "    \"I'm feeling a bit under the weather today.\",\n",
        "    \"Winning the lottery would be a dream come true.\",\n",
        "    \"The customer service I received was terrible; I'm never shopping there again.\",\n",
        "    \"Hiking in the mountains provides a sense of tranquility and peace.\",\n",
        "    \"Getting stuck in a traffic jam on a Monday morning is the worst!\"\n",
        "]\n",
        "for sent in sentences:\n",
        "  encoded_sent = tokenizer(sent, return_tensors = 'pt')\n",
        "  input_ids = encoded_sent['input_ids'].to(device)\n",
        "  attention_msk = encoded_sent['attention_mask'].to(device)\n",
        "  model_output = model(input_ids,attention_msk)\n",
        "  model_output_tensor = torch.tensor(model_output.logits)\n",
        "  model_output_tensor_categoryIndex = int(torch.argmax(model_output_tensor))\n",
        "  print(swapped_dict[model_output_tensor_categoryIndex])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXpP_J6kKC3g"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"I love spending time with my family and friends.\",\n",
        "    \"The movie I watched yesterday was absolutely fantastic!\",\n",
        "    \"Today's weather is gloomy and depressing.\",\n",
        "    \"Learning new things is always exciting and fulfilling.\",\n",
        "    \"Traffic during rush hour drives me crazy; it's so frustrating.\",\n",
        "    \"I'm feeling a bit under the weather today.\",\n",
        "    \"Winning the lottery would be a dream come true.\",\n",
        "    \"The customer service I received was terrible; I'm never shopping there again.\",\n",
        "    \"Hiking in the mountains provides a sense of tranquility and peace.\",\n",
        "    \"Getting stuck in a traffic jam on a Monday morning is the worst!\"\n",
        "]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "papermill": {
      "duration": 535.97462,
      "end_time": "2020-09-25T19:57:10.705412",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-09-25T19:48:14.730792",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}